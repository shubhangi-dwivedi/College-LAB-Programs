{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML-16(NLP_feature_extraction).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**28-03-2022**"
      ],
      "metadata": {
        "id": "wHeD0cioW1SG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature extraction using - Bag-of-words in NLP :"
      ],
      "metadata": {
        "id": "3CdHGCMMapxv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "it is one of the feature extraction tecnique in case of natural language "
      ],
      "metadata": {
        "id": "3IUy9q4iavAH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Jl7h2nxyZdXN"
      },
      "outputs": [],
      "source": [
        "corpus= ['We are all b. Tech students and we are studying ai - ml.', \n",
        "         'We are in Banasthali Vidyapith.', \n",
        "         'We are pursuing computer science.', \n",
        "         'Currently in third year.']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55wP-np7dSJE",
        "outputId": "11960bcb-64e1-4d9f-f484-506fd4c6b2d6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We are all b. Tech students and we are studying ai - ml.',\n",
              " 'We are in Banasthali Vidyapith.',\n",
              " 'We are pursuing computer science.',\n",
              " 'Currently in third year.']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Corpus is needed to create a good dictionary.**\n",
        "\n",
        "**A good dictionary is needed bcz computer can only recognize those stuff which is in the dictionary.**\n",
        "\n",
        "for ex : on google we get good translation for common words(which are there in its dictionary).\n",
        "\n",
        "But sometimes google translator fails to give correct translation bcz the word is not present in its dictionary."
      ],
      "metadata": {
        "id": "SkcbHRmZdiO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features in corpus : \n",
        "\n",
        "there are 2 techniques for feature extraction from corpus :-\n",
        "1. TF-IDF (term frequency-inverse document frequency)\n",
        "2. BAG OF WORDS"
      ],
      "metadata": {
        "id": "ayXiEsweecQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "J77N4D3-kxt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Difference b/w feature selection & extraction : \n",
        "\n",
        "**feature selection** - selection features from given features\n",
        "\n",
        "**feature extraction** - in this we extract the new features not the old ones"
      ],
      "metadata": {
        "id": "030Fcyi8kzny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "nCcdlWNeoCTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "words having high frequency are considered imp."
      ],
      "metadata": {
        "id": "bgJtF-91oD7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "zQ5PVgzjoH7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "one of the application of regular lang/grammar is that it tokenizes words/sentences/paragraph.\n",
        "\n",
        "Using bag-of-words to tokenize in such a way that it'll extract each and every word. \n",
        "\n",
        "here, all the words are tokens.\n",
        "\n",
        "we extract the tokens actually. "
      ],
      "metadata": {
        "id": "nOWZD4QqoR9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag-of-words consists 2 diff. things:\n",
        "\n",
        "1. vocabulary of known words\n",
        "2. and count of words that are present"
      ],
      "metadata": {
        "id": "Z0m8LHfupgXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "df_O30NMrMfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> feature extraction can be from multiple things i.e. text, image, time series data etc. So, it is required to specify from where we want to extract features"
      ],
      "metadata": {
        "id": "Ps5Wdv4wr6Co"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenization :"
      ],
      "metadata": {
        "id": "7tpJmoplrNbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "a23rVTQVrfVq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "in CountVectorizer(), by-default analyzier are single words, we can also take pair of words or more, i.e. n-gram."
      ],
      "metadata": {
        "id": "41_R433P19vI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vc= CountVectorizer() #deafult parameters will be passed\n",
        "#by-default eng stop words will be considered\n",
        "\n",
        "#fitting & transforming th corpus\n",
        "X= vc.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "Q86djYhNsNcp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> printing features(tokens) :"
      ],
      "metadata": {
        "id": "CnUiy-ecspQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vc.get_feature_names_out()\n",
        "\n",
        "#o/p is in sorted order like dictionary\n",
        "\n",
        "# . is considered as a stop word, therefor B. is not there in tokens\n",
        "#there are many stop words in eng. lang.\n",
        "#we can define our stop words in CountVectorizer()\n",
        "#or, we can write to include all the stop words that are popular in eng. lang."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUSg6fT1srcV",
        "outputId": "dd219563-119b-43fc-fdf1-6212348c8b94"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ai', 'all', 'and', 'are', 'banasthali', 'computer', 'currently',\n",
              "       'in', 'ml', 'pursuing', 'science', 'students', 'studying', 'tech',\n",
              "       'third', 'vidyapith', 'we', 'year'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " print(X.toarray())\n",
        "\n",
        " #all words present in the sentence and are there in token will be marked accoring to their count in the sentence, \n",
        " #else if token is not  in the sentence it'll be marked 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFZOH_-Udg0_",
        "outputId": "67c7de15-967a-4b00-f1e8-31fc9c89930a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 2 0 0 0 0 1 0 0 1 1 1 0 0 2 0]\n",
            " [0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0]\n",
            " [0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> if we want to give column names in above matrix :"
      ],
      "metadata": {
        "id": "Lm7AdI5pxXgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "count_token= X.toarray()\n",
        "df=pd.DataFrame(data=count_token, columns=vc.get_feature_names())\n",
        "print(df)\n",
        "\n",
        "#0,1,2,3 for rows is for 4 sentences that we have declared above"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOPt4SBAxfW-",
        "outputId": "cbd35f17-fb45-47e5-b2e1-2768ddbf6bdc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ai  all  and  are  banasthali  computer  currently  in  ml  pursuing  \\\n",
            "0   1    1    1    2           0         0          0   0   1         0   \n",
            "1   0    0    0    1           1         0          0   1   0         0   \n",
            "2   0    0    0    1           0         1          0   0   0         1   \n",
            "3   0    0    0    0           0         0          1   1   0         0   \n",
            "\n",
            "   science  students  studying  tech  third  vidyapith  we  year  \n",
            "0        0         1         1     1      0          0   2     0  \n",
            "1        0         0         0     0      0          1   1     0  \n",
            "2        1         0         0     0      0          0   1     0  \n",
            "3        0         0         0     0      1          0   0     1  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "h16c0daGzC-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> if we want to specify stop words :"
      ],
      "metadata": {
        "id": "l6kI2Y9-zDt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vc= CountVectorizer(stop_words= ['is'])\n",
        "X= vc.fit_transform(corpus)\n",
        "vc.get_feature_names_out()\n",
        "\n",
        "#'is' will be removed from tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVZr_apYzHjn",
        "outputId": "8c273dab-74d2-4e84-d315-1544eff5cc58"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ai', 'all', 'and', 'are', 'banasthali', 'computer', 'currently',\n",
              "       'in', 'ml', 'pursuing', 'science', 'students', 'studying', 'tech',\n",
              "       'third', 'vidyapith', 'we', 'year'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vc= CountVectorizer(min_df=2) #min_df stands for min. document frequency\n",
        "#X= vc.fit_transform(corpus)\n",
        "#vc.get_feature_names_out()"
      ],
      "metadata": {
        "id": "oYui63xn0OoQ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vc1= CountVectorizer(analyzer='word', ngram_range=(2,3))\n",
        "X= vc1.fit_transform(corpus)  # we are passing whole corpus\n",
        "vc1.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxXkPzk-LfFp",
        "outputId": "282d462e-c5d4-4084-864b-2f9271fd862a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ai ml', 'all tech', 'all tech students', 'and we', 'and we are',\n",
              "       'are all', 'are all tech', 'are in', 'are in banasthali',\n",
              "       'are pursuing', 'are pursuing computer', 'are studying',\n",
              "       'are studying ai', 'banasthali vidyapith', 'computer science',\n",
              "       'currently in', 'currently in third', 'in banasthali',\n",
              "       'in banasthali vidyapith', 'in third', 'in third year',\n",
              "       'pursuing computer', 'pursuing computer science', 'students and',\n",
              "       'students and we', 'studying ai', 'studying ai ml',\n",
              "       'tech students', 'tech students and', 'third year', 'we are',\n",
              "       'we are all', 'we are in', 'we are pursuing', 'we are studying'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz2gbE3EQzil",
        "outputId": "7c8901a6-b4c8-49b9-bae5-25df33c011f0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 2 1 0 0 1]\n",
            " [0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "iTO1yzJTRuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for TF-IDF we use TfidfVectorizer()."
      ],
      "metadata": {
        "id": "aqbmBQAHSDhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "jNPTR4_7SJZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Diff. b/w bag-of-words and TF-IDF :** \n",
        "\n",
        "diff. b/w them depends on stop words.\n",
        "\n",
        "In case of TF-IDF the stop words are increased in number. And there is formula, stop words are calculated based on the formula, and in case of bag-of words there is no concept of that formula except of the counting of frequency of particular word in the whole sentence."
      ],
      "metadata": {
        "id": "zmKxuO1xRvjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "0cu3omVhTzYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TF-IDF : "
      ],
      "metadata": {
        "id": "_69HHoSoT5af"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--first learn nd understand formula--"
      ],
      "metadata": {
        "id": "TzPrQjNpWNZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "Y6A_pusKT0Ht"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vc= TfidfVectorizer()\n",
        "X= vc.fit_transform(corpus)  # we are passing whole corpus\n",
        "vc.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POJv9WMEUwFN",
        "outputId": "be7da13c-9e85-46ea-a452-562f9fff03d1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ai', 'all', 'and', 'are', 'banasthali', 'computer', 'currently',\n",
              "       'in', 'ml', 'pursuing', 'science', 'students', 'studying', 'tech',\n",
              "       'third', 'vidyapith', 'we', 'year'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.toarray()) #term frequency formula will be calculated\n",
        "#and then inverse document frequency formula will be calculated\n",
        "\n",
        "#values always lies b/w 0-1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQqzB4jXVhsQ",
        "outputId": "be1b9756-1bbb-4e6d-8a52-5cd7d8750f13"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.31220618 0.31220618 0.31220618 0.39855432 0.         0.\n",
            "  0.         0.         0.31220618 0.         0.         0.31220618\n",
            "  0.31220618 0.31220618 0.         0.         0.39855432 0.        ]\n",
            " [0.         0.         0.         0.34432086 0.53944516 0.\n",
            "  0.         0.42530476 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.53944516 0.34432086 0.        ]\n",
            " [0.         0.         0.         0.32679768 0.         0.51199172\n",
            "  0.         0.         0.         0.51199172 0.51199172 0.\n",
            "  0.         0.         0.         0.         0.32679768 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.52547275 0.41428875 0.         0.         0.         0.\n",
            "  0.         0.         0.52547275 0.         0.         0.52547275]]\n"
          ]
        }
      ]
    }
  ]
}